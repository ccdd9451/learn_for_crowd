{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from collections import namedtuple\n",
    "from matplotlib import mlab\n",
    "from os import makedirs\n",
    "from pickle import dump\n",
    "from path import Path\n",
    "from pdb import set_trace\n",
    "from time import time\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "\n",
    "# File name / Environment / Crowd / AI\n",
    "Simset = namedtuple(\"Simset\", [\"Name\",\"Envs\",\"Crowd\",\"AI\"])\n",
    "Situs = [\n",
    "    Simset(\"All\", *map(bool,\"111\")),\n",
    "    Simset(\"Environment\", *map(bool,\"100\")),\n",
    "    Simset(\"Crowd\", *map(bool,\"010\")),\n",
    "    Simset(\"AI\", *map(bool,\"001\")),\n",
    "]\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('path', default='.')\n",
    "parser.add_argument('--type', type=int, choices=range(4), required=True)\n",
    "parser.add_argument('--info', type=str)\n",
    "\n",
    "\n",
    "def main(p):\n",
    "    print(\"new process\")\n",
    "    current = Situs[p.type]\n",
    "    path = Path(p.path) / current.Name\n",
    "    files = (path).glob(r\"bench*\") + (path).glob(r\"**\\bench*\") \n",
    "    info = {}\n",
    "    print(time()-itime)\n",
    "    benchmark = pd.concat(\n",
    "                    [pd.read_table(file, sep=' ', skiprows=1) for file in files],\n",
    "                    ignore_index = True\n",
    "                    )\n",
    "    info[\"All_data_number\"] = benchmark.shape[0]\n",
    "    benchmark = benchmark[benchmark[\"frames\"] < benchmark[\"frames\"].max()]\n",
    "    info[\"Vaild_data_number\"] = benchmark.shape[0]\n",
    "    col_names = [col_name for col_name in benchmark.columns if \n",
    "                     (col_name.endswith(\"th_obstacle\") and current.Envs) or\n",
    "                     (col_name.endswith(\"th_region\") and current.Crowd) or\n",
    "                     (col_name.endswith(\"th_ai\") and current.AI)]\n",
    "    info[\"Parameter_number\"] = len(col_names)\n",
    "    print(time()-itime)\n",
    "\n",
    "    times = benchmark[\"agent_time_enableds\"].apply(lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float))\n",
    "    print(time()-itime)\n",
    "    lengths = benchmark[\"agent_distance_traveleds\"].apply(lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float))\n",
    "    print(time()-itime)\n",
    "    energies = benchmark[\"agent_ple_energys\"].apply(lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float))\n",
    "    print(time()-itime)\n",
    "    collisions = benchmark[\"collisionTimes\"].apply(lambda x: pd.Series(x.strip(\"( )\").split(','), dtype=float))\n",
    "    print(time()-itime)\n",
    "    confs = []\n",
    "    confs.append((\"param\",\n",
    "                      benchmark[col_names]))\n",
    "    confs.append((\"time\",\n",
    "                    {\n",
    "                    \"time_max\" :times.max(axis=1),\n",
    "                    \"time_min\" :times.min(axis=1),\n",
    "                    \"time_avg\" :times.mean(axis=1)\n",
    "                    }))\n",
    "    confs.append((\"len\",\n",
    "                    {\n",
    "                    \"len_max\" :lengths.max(axis=1),\n",
    "                    \"len_min\" :lengths.min(axis=1),\n",
    "                    \"len_avg\" :lengths.mean(axis=1)\n",
    "                    }))\n",
    "    confs.append((\"ple\",\n",
    "                    {\n",
    "                    \"ple_max\" :energies.max(axis=1),\n",
    "                    \"ple_min\" :energies.min(axis=1),\n",
    "                    \"ple_avg\" :energies.mean(axis=1)\n",
    "                    }))\n",
    "    confs.append((\"cls\",\n",
    "                    {\n",
    "                    \"cls_max\" :collisions.max(axis=1),\n",
    "                    \"cls_min\" :collisions.min(axis=1),\n",
    "                    \"cls_avg\" :collisions.mean(axis=1)\n",
    "                    }))\n",
    "\n",
    "    pickle_output2(**locals())\n",
    "\n",
    "\n",
    "def pickle_output2(confs, path, p, **_):    \n",
    "    x_pre = confs[0][1]\n",
    "    x_pre_col = x_pre.columns[(x_pre - x_pre.mean() > 0.01).any()]\n",
    "    x = x_pre[x_pre_col].as_matrix()\n",
    "    for name, dic in confs[1:]:\n",
    "        y = pd.DataFrame(dic[name+\"_avg\"]).as_matrix().reshape((-1,1))\n",
    "        \n",
    "        with open(path/\"Processed\"/(\"learn_\"+name+\".dat\"), \"wb\") as f:\n",
    "            dump({\"X\":x,\"Y\":y,\"info\":p.info+name}, f)    \n",
    "    \n",
    "def pickle_output(confs, path, **_):    \n",
    "    for name, dic in confs:\n",
    "        conf = pd.DataFrame(dic).as_matrix()\n",
    "        with open(path/\"Processed\"/(name+\".dat\"), \"wb\") as f:\n",
    "            dump(conf, f)\n",
    "            \n",
    "def table_output(confs, path, **_):  \n",
    "    dat = pd.DataFrame()\n",
    "    for name, dic in confs:\n",
    "        dat = pd.concat([dat, pd.DataFrame(dic)], axis=1)\n",
    "    dat.to_csv(path/\"Processed\"/(\"data.dat\"), sep=\" \", float_format='%.6f')\n",
    "            \n",
    "def dist_output(confs, path, **_):\n",
    "    \n",
    "    for name, dic in confs[1:]:\n",
    "        _pic_output(dic[name + \"_avg\"],\n",
    "                   path/\"Processed\"/(name+\".jpg\"))\n",
    "        \n",
    "def info_output(info, path, **_):\n",
    "    with open(path/\"Processed\"/\"info.txt\", \"w\") as f:\n",
    "        yaml.dump(info, f, default_flow_style=False)\n",
    "\n",
    "def _pic_output(data, path):  \n",
    "    plt.clf()\n",
    "    plt.xlim((min(data), max(data)))\n",
    "    plt.hist(data, bins=1000, \n",
    "             normed=True, color=\"gray\", \n",
    "             label=\"Raw Data\")\n",
    "    \n",
    "    mean = np.mean(data)\n",
    "    variance = np.var(data)\n",
    "    sigma = np.sqrt(variance)\n",
    "    x = np.linspace(min(data), max(data), 1000)\n",
    "    plt.plot(x, mlab.normpdf(x, mean, sigma), \n",
    "             color=\"b\", label=\"Gaussian Dist.\")\n",
    "    plt.xlabel(\"mean: {:.2f}, sigma: {:.2f}\"\n",
    "                  .format(mean, sigma))\n",
    "    plt.savefig(path)\n",
    "\n",
    "def whole_output(confs, path, **_):\n",
    "    dat = pd.DataFrame()\n",
    "    for name, dic in confs:\n",
    "        dat = pd.concat([dat, pd.DataFrame(dic)], axis=1)\n",
    "        dat.to_pickle(path/\"df.dat\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    p = parser.parse_args()\n",
    "    main(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itime = time()\n",
    "p = parser.parse_args([r\"C:\\Users\\kaidonghu\\Google Drive\\MIG\\SF\\Map2\",\"--type\",\"0\",\"--info\",\"SF Map2 All \"])\n",
    "main(p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
